{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\LENOVO\\\\1. Projects\\\\Bodycode-Anomaly-Detection-Project\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\LENOVO\\\\1. Projects\\\\Bodycode-Anomaly-Detection-Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_10212\\2985682005.py:6: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import keras_tuner as kt\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from bodycoteAnomalyDetection.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from bodycoteAnomalyDetection.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_ckpt: Path\n",
    "    learning_rate_range: list\n",
    "    batch_size_range: list\n",
    "    epochs_range: list\n",
    "    encoder_units_1_range: list\n",
    "    encoder_units_2_range: list\n",
    "    max_trials: int\n",
    "    executions_per_trial: int\n",
    "    training_epochs: int\n",
    "    training_validation_split: float\n",
    "    training_batch_size: int\n",
    "    num_trials: int\n",
    "    early_stopping_patience: int\n",
    "    restore_best_weights: bool\n",
    "    final_epochs: int\n",
    "    final_batch_size: int\n",
    "    final_validation_split: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.TrainingArguments\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        return ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            model_ckpt=config.model_ckpt,\n",
    "            learning_rate_range=params.learning_rate_range,\n",
    "            batch_size_range=params.batch_size_range,\n",
    "            epochs_range=params.epochs_range,\n",
    "            encoder_units_1_range=params.encoder_units_1_range,\n",
    "            encoder_units_2_range=params.encoder_units_2_range,\n",
    "            max_trials=params.max_trials,\n",
    "            executions_per_trial=params.executions_per_trial,\n",
    "            training_epochs=params.training_epochs,\n",
    "            training_validation_split=params.training_validation_split,\n",
    "            training_batch_size=params.training_batch_size,\n",
    "            num_trials=params.num_trials,\n",
    "            early_stopping_patience=params.early_stopping_patience,\n",
    "            restore_best_weights=params.restore_best_weights,\n",
    "            final_epochs=params.final_epochs,\n",
    "            final_batch_size=params.final_batch_size,\n",
    "            final_validation_split=params.final_validation_split\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.input_shape = None\n",
    "    \n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.config.data_path)\n",
    "        df.set_index('TimeStamp', inplace=True)\n",
    "        return df\n",
    "\n",
    "    def data_scaler(self, df):\n",
    "        scaler = MinMaxScaler()\n",
    "        X_scaled = scaler.fit_transform(df)\n",
    "        scaler_filename = os.path.join(self.config.root_dir, \"scaler_data.joblib\")\n",
    "        joblib.dump(scaler, scaler_filename)\n",
    "        return X_scaled\n",
    "\n",
    "    def data_reshaper(self, X_scaled):\n",
    "        X_reshaped = X_scaled.reshape(X_scaled.shape[0], 1, X_scaled.shape[1])\n",
    "        self.input_shape = X_reshaped.shape[1:]\n",
    "        return X_reshaped\n",
    "\n",
    "    def create_model(self, hp):\n",
    "        input_shape = self.input_shape\n",
    "        encoder_units_1 = hp.Choice('encoder_units_1', self.config.encoder_units_1_range)\n",
    "        encoder_units_2 = hp.Choice('encoder_units_2', self.config.encoder_units_2_range)\n",
    "        learning_rate = hp.Choice('learning_rate', self.config.learning_rate_range)\n",
    "\n",
    "        inputs = Input(shape=input_shape)\n",
    "        x = LSTM(encoder_units_1, activation='relu', return_sequences=True)(inputs)\n",
    "        x = LSTM(encoder_units_2, activation='relu', return_sequences=False)(x)\n",
    "        x = RepeatVector(input_shape[0])(x)\n",
    "        x = LSTM(encoder_units_2, activation='relu', return_sequences=True)(x)\n",
    "        x = LSTM(encoder_units_1, activation='relu', return_sequences=True)(x)\n",
    "        output = TimeDistributed(Dense(input_shape[1]))(x)\n",
    "        model = Model(inputs=inputs, outputs=output)\n",
    "        model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mae')\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        df = self.load_data()\n",
    "        X_scaled = self.data_scaler(df)\n",
    "        X_train = self.data_reshaper(X_scaled)\n",
    "\n",
    "        tuner = kt.RandomSearch(\n",
    "            self.create_model,\n",
    "            objective='val_loss',\n",
    "            max_trials=self.config.max_trials,\n",
    "            executions_per_trial=self.config.executions_per_trial,\n",
    "            directory=os.path.join(self.config.root_dir, 'my_dir'),\n",
    "            project_name='hparam_tuning'\n",
    "        )\n",
    "\n",
    "        tuner.search_space_summary()\n",
    "        tuner.search(X_train, X_train, \n",
    "                     epochs=self.config.training_epochs,\n",
    "                     validation_split=self.config.training_validation_split,\n",
    "                     batch_size=self.config.training_batch_size)\n",
    "\n",
    "        best_hps = tuner.get_best_hyperparameters(num_trials=self.config.num_trials)[0]\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                                       patience=self.config.early_stopping_patience, \n",
    "                                       restore_best_weights=self.config.restore_best_weights)\n",
    "        \n",
    "        model = tuner.hypermodel.build(best_hps)\n",
    "        history = model.fit(X_train, X_train, \n",
    "                            epochs=self.config.final_epochs, \n",
    "                            batch_size=self.config.final_batch_size, \n",
    "                            validation_split=self.config.final_validation_split, \n",
    "                            callbacks=[early_stopping]\n",
    "                            )\n",
    "\n",
    "        model.save(os.path.join(self.config.root_dir, \"anomaly_detector_model.keras\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-04 23:09:47,453: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-01-04 23:09:47,472: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-01-04 23:09:47,472: INFO: common: created directory at: artifacts]\n",
      "[2024-01-04 23:09:47,480: INFO: common: created directory at: artifacts/model_trainer]\n",
      "Reloading Tuner from artifacts/model_trainer\\my_dir\\hparam_tuning\\tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 3\n",
      "encoder_units_1 (Choice)\n",
      "{'default': 32, 'conditions': [], 'values': [32, 64, 128], 'ordered': True}\n",
      "encoder_units_2 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.001, 'conditions': [], 'values': [0.001, 0.01, 0.1], 'ordered': True}\n",
      "WARNING:tensorflow:From c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "[2024-01-04 23:09:48,566: WARNING: module_wrapper: From c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "]\n",
      "WARNING:tensorflow:From c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "[2024-01-04 23:09:51,139: WARNING: module_wrapper: From c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "]\n",
      "14394/14394 [==============================] - 174s 11ms/step - loss: 0.0155 - val_loss: 0.0074\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager()\n",
    "    model_trainer_config = config_manager.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer.train()\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
